{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf lvlm-interpret"
      ],
      "metadata": {
        "id": "I8OF4-puDU3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHmA4Kjue7ap",
        "outputId": "b1f4d08a-584e-46e3-8bf3-0fdd5b2c5ad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lvlm-interpret'...\n",
            "remote: Enumerating objects: 100, done.\u001b[K\n",
            "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 100 (delta 49), reused 68 (delta 26), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (100/100), 117.31 KiB | 889.00 KiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/adishourya/lvlm-interpret"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd lvlm-interpret"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIDjOvOhfHiV",
        "outputId": "63522073-e390-472c-a5a2-131d380e8c9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyPQBObbfNV_",
        "outputId": "660b2970-bc94-4f72-a65c-eab89dd96f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py\t\t\t  __pycache__\t    utils_attn.py\t\t  utils_model.py\n",
            "causality_lab\t\t  README.md\t    utils_causal_discovery_fn.py  utils_relevancy.py\n",
            "LICENSE\t\t\t  requirements.txt  utils_causal_discovery.py\n",
            "processing_llavagemma.py  Security.md\t    utils_gradio.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git submodule update --init --recursive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjAj7ywKfOat",
        "outputId": "08a46ee7-c628-4fcf-d359-72aee114a5fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submodule 'causality-lab' (https://github.com/IntelLabs/causality-lab.git) registered for path 'causality_lab'\n",
            "Cloning into '/content/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/causality_lab'...\n",
            "Submodule path 'causality_lab': checked out '4282eb1ef008a91b29a1df9e93dee8162be8486f'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEfVDWtWfULU",
        "outputId": "f51bc5df-d1c3-4cd0-97b8-bc011e693f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.20.1+cu121)\n",
            "Requirement already satisfied: transformers>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.46.3)\n",
            "Requirement already satisfied: gradio>=4.36.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (5.8.0)\n",
            "Requirement already satisfied: spaces in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.30.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (11.0.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (3.8.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.13.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.13.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (0.45.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.41.1->-r requirements.txt (line 3)) (0.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.41.1->-r requirements.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.41.1->-r requirements.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.41.1->-r requirements.txt (line 3)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.41.1->-r requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.41.1->-r requirements.txt (line 3)) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.41.1->-r requirements.txt (line 3)) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.41.1->-r requirements.txt (line 3)) (4.66.6)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.36.1->-r requirements.txt (line 4)) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.36.1->-r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.36.1->-r requirements.txt (line 4)) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio>=4.36.1->-r requirements.txt (line 4)) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.5.1 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.36.1->-r requirements.txt (line 4)) (1.5.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.36.1->-r requirements.txt (line 4)) (0.28.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.36.1->-r requirements.txt (line 4)) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.36.1->-r requirements.txt (line 4)) (3.10.12)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.36.1->-r requirements.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.36.1->-r requirements.txt (line 4)) (2.10.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio>=4.36.1->-r requirements.txt (line 4)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.36.1->-r requirements.txt (line 4)) (0.0.19)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.36.1->-r requirements.txt (line 4)) (0.8.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.36.1->-r requirements.txt (line 4)) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.36.1->-r requirements.txt (line 4)) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.36.1->-r requirements.txt (line 4)) (0.41.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.36.1->-r requirements.txt (line 4)) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.36.1->-r requirements.txt (line 4)) (0.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.36.1->-r requirements.txt (line 4)) (0.32.1)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio>=4.36.1->-r requirements.txt (line 4)) (14.1)\n",
            "Requirement already satisfied: psutil<6,>=2 in /usr/local/lib/python3.10/dist-packages (from spaces->-r requirements.txt (line 5)) (5.9.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.36.1->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.36.1->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.36.1->-r requirements.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.36.1->-r requirements.txt (line 4)) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.36.1->-r requirements.txt (line 4)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio>=4.36.1->-r requirements.txt (line 4)) (0.14.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio>=4.36.1->-r requirements.txt (line 4)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio>=4.36.1->-r requirements.txt (line 4)) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio>=4.36.1->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio>=4.36.1->-r requirements.txt (line 4)) (2.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 8)) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.41.1->-r requirements.txt (line 3)) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.41.1->-r requirements.txt (line 3)) (2.2.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.36.1->-r requirements.txt (line 4)) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.36.1->-r requirements.txt (line 4)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.36.1->-r requirements.txt (line 4)) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.36.1->-r requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.36.1->-r requirements.txt (line 4)) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.36.1->-r requirements.txt (line 4)) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python app.py --embed --share  --load_4bit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpWs6cX0fa7W",
        "outputId": "30ef2ab4-5ae0-4410-99c6-19ef6d1dc584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-10 13:16:48.582710: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-10 13:16:48.600616: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-10 13:16:48.621775: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-10 13:16:48.628270: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-10 13:16:48.643562: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-10 13:16:49.948972: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "Loading checkpoint shards: 100% 3/3 [00:03<00:00,  1.24s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:237: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  warnings.warn(\n",
            "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
            "* Running on local URL:  http://0.0.0.0:7860\n",
            "INFO:httpx:HTTP Request: GET http://localhost:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD http://localhost:7860/ \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n",
            "* Running on public URL: https://126cdccc7f1696c28b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "INFO:utils_gradio:is the person happy , and is the balloon orange ?\n",
            "You may have used the wrong order for inputs. `images` should be passed before `text`. The `images` and `text` inputs will be swapped. This behavior will be deprecated in transformers v4.47.\n",
            "Expanding inputs for image tokens in LLaVa should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.\n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "WARNING:utils_model:Attention weights were not returned for the vision model. Relevancy maps will not be calculated for the vision model. To enable, set output_attentions=True in the forward pass of vision_tower. \n",
            "Expanding inputs for image tokens in LLaVa should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.\n",
            "GemmaModel is using GemmaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
            "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n",
            "INFO:utils_gradio:Generated response: Yes, the person is happy, and the balloon is green.<end_of_turn>\n",
            "INFO:utils_gradio:Saved attention to /tmp/tmpmwb__y0w_attn.pt\n",
            "INFO:utils_gradio:Saved relevancy map to /tmp/tmpmwb__y0w_relevancy.pt\n",
            "/content/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/utils_attn.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  attentions = torch.load(fn_attention, mmap=True)\n",
            "/content/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/utils_attn.py:362: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  attentions = torch.load(fn_attention)\n",
            "INFO:utils_attn:Loaded attention from /tmp/tmpmwb__y0w_attn.pt\n",
            "/content/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/utils_attn.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  attentions = torch.load(fn_attention)\n",
            "INFO:utils_attn:Loaded attention from /tmp/tmpmwb__y0w_attn.pt\n",
            "/content/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/utils_attn.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  attentions = torch.load(fn_attention)\n",
            "INFO:utils_attn:Loaded attention from /tmp/tmpmwb__y0w_attn.pt\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2865, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/lvlm-interpret/app.py\", line 32, in <module>\n",
            "    demo.launch(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2770, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2867, in block_thread\n",
            "    print(\"Keyboard interruption in main thread... closing server.\")\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 0.0.0.0:7860 <> https://126cdccc7f1696c28b.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gradio deploy"
      ],
      "metadata": {
        "id": "q0d5NseWfmnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /tmp | grep attn"
      ],
      "metadata": {
        "id": "oKa7wzCWHoFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6771abe8-345c-4f74-ca14-2e69bffff75b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tmp4yeralg2_attn.pt\n",
            "tmp78grm7zu_attn.pt\n",
            "tmpab25ol83_attn.pt\n",
            "tmpb8v5f6hm_attn.pt\n",
            "tmpdg_540sv_attn.pt\n",
            "tmpe_mj8czf_attn.pt\n",
            "tmpfzc0talm_attn.pt\n",
            "tmph27gyuwv_attn.pt\n",
            "tmpl1thiwry_attn.pt\n",
            "tmpmwb__y0w_attn.pt\n",
            "tmpqh5zkgmi_attn.pt\n",
            "tmpt49x79i9_attn.pt\n",
            "tmpuls7i7h6_attn.pt\n",
            "tmpy7cl61vn_attn.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lNtgVPEYuuYJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}